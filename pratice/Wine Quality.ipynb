{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error,r2_score , accuracy_score\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "dataset_url = 'http://mlr.cs.umass.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "data = pd.read_csv(dataset_url, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.319637</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>10.422983</td>\n",
       "      <td>5.636023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.741096</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>0.807569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
       "mean        8.319637          0.527821     0.270976        2.538806   \n",
       "std         1.741096          0.179060     0.194801        1.409928   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.390000     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.260000        2.200000   \n",
       "75%         9.200000          0.640000     0.420000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
       "mean      0.087467            15.874922             46.467792     0.996747   \n",
       "std       0.047065            10.460157             32.895324     0.001887   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             22.000000     0.995600   \n",
       "50%       0.079000            14.000000             38.000000     0.996750   \n",
       "75%       0.090000            21.000000             62.000000     0.997835   \n",
       "max       0.611000            72.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  1599.000000  1599.000000  1599.000000  1599.000000  \n",
       "mean      3.311113     0.658149    10.422983     5.636023  \n",
       "std       0.154386     0.169507     1.065668     0.807569  \n",
       "min       2.740000     0.330000     8.400000     3.000000  \n",
       "25%       3.210000     0.550000     9.500000     5.000000  \n",
       "50%       3.310000     0.620000    10.200000     6.000000  \n",
       "75%       3.400000     0.730000    11.100000     6.000000  \n",
       "max       4.010000     2.000000    14.900000     8.000000  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)\n",
    "data.shape\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.quality\n",
    "x = data.drop('quality',axis=1)\n",
    "\n",
    "x_train,x_test,y_train,y_test =  train_test_split(x,y,test_size=0.2,random_state=123,stratify=y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'randomforestregressor': RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                       max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False),\n",
       " 'randomforestregressor__bootstrap': True,\n",
       " 'randomforestregressor__criterion': 'mse',\n",
       " 'randomforestregressor__max_depth': None,\n",
       " 'randomforestregressor__max_features': 'auto',\n",
       " 'randomforestregressor__max_leaf_nodes': None,\n",
       " 'randomforestregressor__min_impurity_decrease': 0.0,\n",
       " 'randomforestregressor__min_impurity_split': None,\n",
       " 'randomforestregressor__min_samples_leaf': 1,\n",
       " 'randomforestregressor__min_samples_split': 2,\n",
       " 'randomforestregressor__min_weight_fraction_leaf': 0.0,\n",
       " 'randomforestregressor__n_estimators': 100,\n",
       " 'randomforestregressor__n_jobs': None,\n",
       " 'randomforestregressor__oob_score': False,\n",
       " 'randomforestregressor__random_state': None,\n",
       " 'randomforestregressor__verbose': 0,\n",
       " 'randomforestregressor__warm_start': False,\n",
       " 'standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'standardscaler__copy': True,\n",
       " 'standardscaler__with_mean': True,\n",
       " 'standardscaler__with_std': True,\n",
       " 'steps': [('standardscaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('randomforestregressor',\n",
       "   RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                         max_features='auto', max_leaf_nodes=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                         n_jobs=None, oob_score=False, random_state=None,\n",
       "                         verbose=0, warm_start=False))],\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = preprocessing.StandardScaler().fit(x_train)\n",
    "\n",
    "x_scaled_tarin = scalar.transform(x_train)\n",
    "x_scaled_test = scalar.transform(x_test)\n",
    "\n",
    "\n",
    "pipeline = make_pipeline(preprocessing.StandardScaler(), \n",
    "                         RandomForestRegressor(n_estimators=100))\n",
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = { 'randomforestregressor__max_features' : ['auto', 'sqrt', 'log2'],\n",
    "                  'randomforestregressor__max_depth': [None, 5, 3, 1]}\n",
    "clf = GridSearchCV(pipeline, hyperparameters, cv=10)\n",
    " \n",
    "# Fit and tune model\n",
    "clf.fit(x_train, y_train)\n",
    "clf.refit\n",
    "\n",
    "y_predict = clf.predict(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.468547975059023\n",
      "0.342931875\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(r2_score(y_test, y_predict))\n",
    "\n",
    "print(mean_squared_error(y_test, y_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_regressor.pkl']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save the model\n",
    "\n",
    "joblib.dump(clf,'rf_regressor.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.5 , 5.75, 4.96, 5.37, 6.22, 5.6 , 4.96, 4.71, 5.01, 6.27, 5.35,\n",
       "       5.75, 5.87, 5.02, 5.74, 5.72, 6.51, 5.71, 5.79, 6.96, 5.46, 5.69,\n",
       "       5.02, 6.01, 5.91, 5.06, 5.43, 5.17, 5.84, 5.91, 5.89, 6.31, 5.98,\n",
       "       5.04, 4.96, 5.98, 5.09, 6.23, 5.01, 6.11, 4.96, 5.95, 6.67, 5.12,\n",
       "       6.19, 5.46, 5.54, 5.61, 5.11, 6.37, 6.11, 5.38, 5.81, 5.22, 5.68,\n",
       "       5.75, 5.25, 5.37, 4.99, 5.31, 5.3 , 5.19, 5.06, 5.78, 5.92, 5.23,\n",
       "       6.42, 5.06, 5.2 , 6.71, 5.77, 5.67, 5.06, 5.01, 5.38, 6.  , 5.28,\n",
       "       5.15, 5.29, 5.26, 6.37, 5.62, 6.21, 6.51, 5.08, 6.06, 6.34, 6.34,\n",
       "       5.61, 5.86, 5.96, 5.32, 6.37, 5.76, 5.73, 5.78, 6.72, 6.78, 5.61,\n",
       "       6.7 , 5.03, 5.49, 5.13, 6.55, 5.06, 4.8 , 5.66, 4.94, 5.75, 5.93,\n",
       "       5.81, 5.54, 6.04, 5.37, 5.19, 5.23, 5.99, 5.11, 5.1 , 6.07, 5.91,\n",
       "       5.09, 5.74, 6.15, 5.26, 5.42, 5.33, 5.88, 5.57, 5.4 , 5.86, 6.4 ,\n",
       "       5.16, 5.21, 4.98, 6.39, 5.02, 5.26, 6.77, 5.37, 5.17, 5.11, 5.71,\n",
       "       6.1 , 5.31, 5.44, 5.13, 6.31, 5.79, 5.06, 5.59, 5.26, 4.98, 4.97,\n",
       "       5.22, 5.95, 5.39, 5.85, 5.78, 5.25, 5.56, 5.09, 5.28, 5.94, 5.1 ,\n",
       "       5.98, 5.16, 5.3 , 5.39, 5.17, 5.95, 5.06, 5.72, 5.11, 5.68, 5.44,\n",
       "       5.12, 5.43, 5.62, 5.06, 5.98, 5.52, 5.08, 4.97, 5.12, 6.12, 5.21,\n",
       "       5.48, 5.35, 4.97, 5.47, 6.56, 5.83, 5.87, 5.39, 5.22, 5.51, 5.08,\n",
       "       6.36, 4.71, 6.32, 5.09, 5.28, 5.14, 6.81, 6.07, 5.17, 5.22, 5.45,\n",
       "       5.87, 5.72, 5.92, 6.  , 6.2 , 5.76, 5.98, 5.23, 5.31, 5.72, 5.36,\n",
       "       5.27, 6.11, 6.04, 5.53, 5.84, 5.84, 5.59, 6.21, 5.44, 5.74, 5.38,\n",
       "       5.46, 6.26, 5.62, 4.68, 4.5 , 6.55, 6.48, 6.23, 5.26, 5.48, 5.44,\n",
       "       5.55, 6.28, 6.05, 5.18, 5.12, 5.36, 5.4 , 6.34, 5.13, 5.07, 5.25,\n",
       "       5.1 , 6.  , 6.45, 5.68, 5.42, 5.59, 6.42, 5.55, 6.03, 5.27, 5.19,\n",
       "       5.69, 5.89, 5.77, 5.58, 5.48, 5.1 , 5.72, 5.52, 6.51, 6.03, 5.59,\n",
       "       5.08, 6.04, 6.4 , 5.93, 5.43, 5.65, 5.34, 5.35, 6.03, 6.89, 5.33,\n",
       "       6.45, 5.8 , 5.38, 5.43, 5.58, 5.17, 5.19, 6.2 , 5.71, 5.93, 5.98,\n",
       "       5.88, 5.44, 5.58, 5.56, 6.11, 5.67, 6.92, 6.6 , 5.92, 6.28, 5.1 ,\n",
       "       5.24, 5.98, 5.35, 5.46, 6.02, 6.5 , 6.29, 5.31, 5.56, 5.69, 6.08,\n",
       "       5.57])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = joblib.load('rf_regressor.pkl')\n",
    "clf2.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 6 6 5 5 6 6 5 5 6 5 6 6 5 6 6 6 6 6 7 5 6 5 6 6 5 6 5 6 6 6 5 6 5 5 5 5\n",
      " 6 5 6 6 6 6 5 6 5 6 5 5 6 6 5 6 5 5 5 6 5 5 5 6 5 5 6 7 5 6 5 5 7 5 6 5 5\n",
      " 6 6 5 5 5 5 6 5 6 5 5 5 5 6 6 5 6 6 7 6 6 6 5 6 5 7 5 6 5 7 5 5 6 5 5 6 7\n",
      " 5 6 6 6 6 6 5 5 5 5 5 6 6 5 6 6 6 5 6 5 7 5 5 5 5 5 5 5 6 5 5 5 6 5 6 5 5\n",
      " 6 6 5 5 5 5 5 6 5 6 6 5 5 5 5 5 5 6 6 5 6 5 6 5 6 5 5 5 6 5 6 5 6 5 6 5 5\n",
      " 6 5 5 6 6 6 6 6 6 6 5 6 5 6 5 6 5 5 5 6 7 6 5 5 6 6 7 6 6 6 6 6 5 6 5 5 6\n",
      " 6 5 6 5 5 5 5 5 5 5 5 5 5 5 7 6 6 6 6 6 5 6 6 5 5 6 6 6 6 5 5 5 5 6 6 6 5\n",
      " 6 6 6 5 6 5 6 6 6 5 5 5 5 7 6 5 6 6 6 6 5 6 5 5 5 6 6 6 6 5 6 5 6 5 6 6 6\n",
      " 6 6 6 6 5 5 5 6 6 6 7 5 5 5 5 6 5 6 6 5 6 5 6 5]\n",
      "Accuracy of Decision Tree is:  0.61875\n",
      "mean square error :  0.61875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jitu/.local/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Support Vector Machine is:  0.571875\n",
      "mean square error :  0.603125\n",
      "Accuracy of K-Nearest Neighbors is:  0.496875\n",
      "mean square error :  0.74375\n",
      "Accuracy of Logistic Regression is:  0.553125\n",
      "mean square error :  0.559375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jitu/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree, svm, neighbors, linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf2 = svm.SVC()\n",
    "clf3 = neighbors.KNeighborsClassifier()\n",
    "clf4 = linear_model.LogisticRegression(solver=\"liblinear\",C=1)\n",
    "\n",
    "\n",
    "\n",
    "# clf = clf.fit(x_scaled_tarin , y_train)\n",
    "# prediction1 = clf.predict(x_scaled_test)\n",
    "# print(prediction1)\n",
    "print(prediction2)\n",
    "\n",
    "\n",
    "clf = clf.fit(x_train, y_train)\n",
    "prediction1 = clf.predict(x_test)\n",
    "acc_clf = accuracy_score(y_test, prediction1)\n",
    "print('Accuracy of Decision Tree is: ', acc_clf)\n",
    "print('mean square error : ',mean_squared_error(y_test, prediction1))\n",
    "\n",
    "clf2 = clf2.fit(x_train, y_train)\n",
    "prediction2 = clf2.predict(x_test)\n",
    "acc_clf2 = accuracy_score(y_test, prediction2)\n",
    "print('Accuracy of Support Vector Machine is: ', acc_clf2)\n",
    "print('mean square error : ',mean_squared_error(y_test, prediction2))\n",
    "\n",
    "\n",
    "clf3 = clf3.fit(x_train, y_train)\n",
    "prediction3 = clf3.predict(x_test)\n",
    "acc_clf3 = accuracy_score(y_test, prediction3)\n",
    "print('Accuracy of K-Nearest Neighbors is: ', acc_clf3)\n",
    "print('mean square error : ',mean_squared_error(y_test, prediction3))\n",
    "\n",
    "\n",
    "clf4 = clf4.fit(x_train, y_train)\n",
    "prediction4 = clf4.predict(x_test)\n",
    "acc_clf4 = accuracy_score(y_test, prediction4)\n",
    "print('Accuracy of Logistic Regression is: ', acc_clf4)\n",
    "print('mean square error : ',mean_squared_error(y_test, prediction4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
